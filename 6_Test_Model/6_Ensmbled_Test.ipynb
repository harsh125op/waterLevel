{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout, Flatten,Attention, Concatenate, Input ,Reshape ,MultiHeadAttention\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,precision_score\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras import backend as K\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"/Users/I578087/Desktop/WaterLevel-main/data_2/dataset.csv\"\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Feature1  300 non-null    float64\n",
      " 1   Feature2  300 non-null    float64\n",
      " 2   Feature3  300 non-null    float64\n",
      " 3   Feature4  300 non-null    float64\n",
      " 4   Feature5  300 non-null    int64  \n",
      " 5   Feature6  300 non-null    int64  \n",
      " 6   Feature7  300 non-null    float64\n",
      " 7   Feature8  300 non-null    float64\n",
      "dtypes: float64(6), int64(2)\n",
      "memory usage: 18.9 KB\n"
     ]
    }
   ],
   "source": [
    "data.drop(['Feature9'],axis=1,inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Standardize the data\n",
    "data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(273, 8, 8)\n",
      "(273, 20, 8)\n"
     ]
    }
   ],
   "source": [
    "# Create sequences for training (8 rows per year)\n",
    "def create_sequences(data, seq_length=8, pred_length=20):\n",
    "    X, y = [], []\n",
    "    # Ensure the data is in numpy array format\n",
    "    data = np.array(data)\n",
    "    \n",
    "    for i in range(len(data) - seq_length - pred_length + 1):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length:i+seq_length+pred_length])  # Predict the next pred_length steps\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Generate sequences\n",
    "X, y = create_sequences(data, seq_length=8, pred_length=20)\n",
    "\n",
    "# Print shapes\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_sequences(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets (use last 20 rows for testing)\n",
    "X_train = X[:-20]\n",
    "y_train = y[:-20]\n",
    "X_test = X[-20:]\n",
    "y_test = y[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LayerNormalization, MultiHeadAttention\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def mape(y_true, y_pred):\n",
    "    return K.mean(K.abs((y_true - y_pred) / K.clip(K.abs(y_true), K.epsilon(), None))) * 100\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, K.round(y_pred)))\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/I578087/Desktop/WaterLevel-main/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 22 variables whereas the saved optimizer has 42 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import LayerNormalization, MultiHeadAttention\n",
    "\n",
    "# Define custom objects\n",
    "custom_objects = {\n",
    "    'LayerNormalization': LayerNormalization,\n",
    "    'MultiHeadAttention': MultiHeadAttention,\n",
    "    'rmse': rmse,\n",
    "    'mape': mape,\n",
    "    'accuracy': accuracy,\n",
    "    'precision': precision\n",
    "}\n",
    "\n",
    "# Load the model with custom objects\n",
    "model1 = load_model(r'/Users/I578087/Desktop/WaterLevel-main/Models/Test/RNN_test.keras', custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model2 = load_model(r'/Users/I578087/Desktop/WaterLevel-main/Models/Test/LSTM_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x1551b6c00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x1551b6c00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
      "Predictions:  [[[-1.4668242  -1.5068566  -1.5583725  ... -1.0436114   1.238088\n",
      "   -1.4012194 ]\n",
      "  [-1.4977429  -1.5695765  -1.5366007  ... -0.9657346   1.3785352\n",
      "   -1.4264958 ]\n",
      "  [-1.5330777  -1.5577582  -1.6020103  ... -0.9993347   1.4941614\n",
      "   -1.5514101 ]\n",
      "  ...\n",
      "  [-1.2171576  -1.2740614  -1.2720159  ... -0.90501547  0.9753388\n",
      "   -1.2026341 ]\n",
      "  [-1.263959   -1.2134795  -1.3233235  ... -1.0152754   0.94734895\n",
      "   -1.1410606 ]\n",
      "  [-1.218692   -1.2322642  -1.2121483  ... -0.9676005   0.9131253\n",
      "   -1.1922312 ]]\n",
      "\n",
      " [[-1.4671286  -1.5063844  -1.556103   ... -1.0461738   1.2368788\n",
      "   -1.3998781 ]\n",
      "  [-1.4968276  -1.5694723  -1.5338957  ... -0.9684894   1.3753179\n",
      "   -1.4253428 ]\n",
      "  [-1.5297236  -1.5547131  -1.5983301  ... -1.0011445   1.4877023\n",
      "   -1.5503016 ]\n",
      "  ...\n",
      "  [-1.2134919  -1.2683647  -1.2684076  ... -0.8999457   0.9736886\n",
      "   -1.1992401 ]\n",
      "  [-1.2613332  -1.2094451  -1.3170652  ... -1.0082002   0.94683623\n",
      "   -1.137188  ]\n",
      "  [-1.2137617  -1.2267977  -1.2058083  ... -0.9574343   0.91308737\n",
      "   -1.186022  ]]\n",
      "\n",
      " [[-1.4674813  -1.510463   -1.5679823  ... -1.0374765   1.2444761\n",
      "   -1.4072067 ]\n",
      "  [-1.5029426  -1.5721447  -1.5468858  ... -0.958428    1.391147\n",
      "   -1.4313844 ]\n",
      "  [-1.5450728  -1.5691892  -1.615652   ... -0.99520916  1.5162122\n",
      "   -1.5571514 ]\n",
      "  ...\n",
      "  [-1.2289066  -1.2924523  -1.2848274  ... -0.921517    0.9816729\n",
      "   -1.2144493 ]\n",
      "  [-1.2732164  -1.226681   -1.3447915  ... -1.037474    0.9511688\n",
      "   -1.1537844 ]\n",
      "  [-1.2340512  -1.2496046  -1.2325078  ... -0.99856013  0.9147881\n",
      "   -1.2113142 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1.4473345  -1.4871118  -1.5243113  ... -1.0580869   1.1991328\n",
      "   -1.3716677 ]\n",
      "  [-1.4711537  -1.5505035  -1.4859259  ... -0.9872407   1.3075688\n",
      "   -1.3971401 ]\n",
      "  [-1.4794698  -1.5033122  -1.5456222  ... -1.0076884   1.3725365\n",
      "   -1.5196685 ]\n",
      "  ...\n",
      "  [-1.1530894  -1.1793678  -1.2105722  ... -0.82070416  0.9545497\n",
      "   -1.1438895 ]\n",
      "  [-1.2044342  -1.1361303  -1.2378948  ... -0.9110344   0.9356402\n",
      "   -1.0780377 ]\n",
      "  [-1.1401302  -1.1434535  -1.1244776  ... -0.82627434  0.9127474\n",
      "   -1.1033258 ]]\n",
      "\n",
      " [[-1.4464326  -1.4847486  -1.5235199  ... -1.0482299   1.1910876\n",
      "   -1.3690982 ]\n",
      "  [-1.4759169  -1.5499802  -1.4867711  ... -0.97615254  1.3142912\n",
      "   -1.3983259 ]\n",
      "  [-1.4854877  -1.5059407  -1.5518605  ... -1.0003558   1.3902856\n",
      "   -1.5287827 ]\n",
      "  ...\n",
      "  [-1.1667478  -1.1982424  -1.2221644  ... -0.8422222   0.9367238\n",
      "   -1.1550877 ]\n",
      "  [-1.2151786  -1.1570016  -1.2570385  ... -0.93922776  0.9219761\n",
      "   -1.0897388 ]\n",
      "  [-1.1589036  -1.164145   -1.1435714  ... -0.8618993   0.90107274\n",
      "   -1.1209061 ]]\n",
      "\n",
      " [[-1.44506    -1.4862487  -1.5301489  ... -1.039494    1.1941386\n",
      "   -1.3729619 ]\n",
      "  [-1.4781635  -1.5499787  -1.4937373  ... -0.9668839   1.3229872\n",
      "   -1.4005842 ]\n",
      "  [-1.4951437  -1.5146421  -1.5625368  ... -0.9941208   1.4093595\n",
      "   -1.5311186 ]\n",
      "  ...\n",
      "  [-1.1771955  -1.2150598  -1.2318485  ... -0.85781     0.93915343\n",
      "   -1.16534   ]\n",
      "  [-1.2230963  -1.1689075  -1.275928   ... -0.9627293   0.92168546\n",
      "   -1.1013412 ]\n",
      "  [-1.1739968  -1.181378   -1.1636404  ... -0.89525366  0.89984536\n",
      "   -1.1402506 ]]]\n"
     ]
    }
   ],
   "source": [
    "#Make predictions\n",
    "y_pred1 = model1.predict(X_test)\n",
    "\n",
    "# Print predictions\n",
    "print(\"Predictions: \", y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x1551b7e20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x1551b7e20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "Predictions:  [[[-1.5075035  -1.5930716  -1.6001717  ... -1.1188248   1.3619933\n",
      "   -1.4421372 ]\n",
      "  [-1.5256069  -1.5537875  -1.632324   ... -1.0357428   1.4178135\n",
      "   -1.3887614 ]\n",
      "  [-1.5156928  -1.6076264  -1.525548   ... -1.060903    1.4458565\n",
      "   -1.5052351 ]\n",
      "  ...\n",
      "  [-1.3593801  -1.3743854  -1.3821052  ... -0.9034008   1.3086367\n",
      "   -1.3569803 ]\n",
      "  [-1.4275851  -1.4679546  -1.3648156  ... -0.9460331   1.2236316\n",
      "   -1.2849902 ]\n",
      "  [-1.3713567  -1.437009   -1.3670635  ... -0.87898815  1.227767\n",
      "   -1.3194577 ]]\n",
      "\n",
      " [[-1.502134   -1.5852344  -1.5910382  ... -1.112784    1.3586737\n",
      "   -1.4361103 ]\n",
      "  [-1.5205667  -1.548575   -1.6234928  ... -1.0305029   1.4107542\n",
      "   -1.3814107 ]\n",
      "  [-1.5095645  -1.6009109  -1.5191474  ... -1.0552015   1.4382645\n",
      "   -1.4981288 ]\n",
      "  ...\n",
      "  [-1.3505225  -1.3630806  -1.3717716  ... -0.8961766   1.2974566\n",
      "   -1.3446465 ]\n",
      "  [-1.4150194  -1.4559762  -1.3517029  ... -0.9399293   1.2152613\n",
      "   -1.2753857 ]\n",
      "  [-1.3611832  -1.4251331  -1.3543054  ... -0.871709    1.2169739\n",
      "   -1.3095545 ]]\n",
      "\n",
      " [[-1.5104476  -1.5944798  -1.6046417  ... -1.1181042   1.3632842\n",
      "   -1.4462591 ]\n",
      "  [-1.5275021  -1.5565829  -1.6347831  ... -1.0349405   1.4201174\n",
      "   -1.3904976 ]\n",
      "  [-1.5183146  -1.6092257  -1.5296037  ... -1.0590855   1.4507103\n",
      "   -1.5050442 ]\n",
      "  ...\n",
      "  [-1.3601383  -1.3708096  -1.3795546  ... -0.90438104  1.3017426\n",
      "   -1.3542026 ]\n",
      "  [-1.4286846  -1.4675756  -1.3619823  ... -0.9473476   1.2164496\n",
      "   -1.2819605 ]\n",
      "  [-1.3680549  -1.4357843  -1.3630983  ... -0.8787967   1.2203654\n",
      "   -1.3205651 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1.2128562  -1.157489   -1.147747   ... -0.64022774  1.1397542\n",
      "   -1.0360725 ]\n",
      "  [-1.2395208  -1.2211221  -1.2689264  ... -0.51509535  1.0871675\n",
      "   -1.0546627 ]\n",
      "  [-1.173829   -1.168835   -1.103744   ... -0.49344334  0.97533685\n",
      "   -1.1430349 ]\n",
      "  ...\n",
      "  [-1.122654   -0.98098063 -0.96417934 ... -0.669125    0.746153\n",
      "   -1.0951183 ]\n",
      "  [-1.0589879  -1.1020411  -0.9180623  ... -0.7398003   0.7052418\n",
      "   -1.0207876 ]\n",
      "  [-0.9986111  -1.1056081  -0.8876251  ... -0.7213258   0.6298226\n",
      "   -0.9915582 ]]\n",
      "\n",
      " [[-1.3008173  -1.2565372  -1.2365004  ... -0.751323    1.1950687\n",
      "   -1.1209375 ]\n",
      "  [-1.325137   -1.3085208  -1.3609623  ... -0.61869484  1.1700323\n",
      "   -1.1264741 ]\n",
      "  [-1.2669376  -1.262448   -1.2018626  ... -0.6067019   1.057438\n",
      "   -1.2281647 ]\n",
      "  ...\n",
      "  [-1.1809065  -1.0544312  -1.0456887  ... -0.7260857   0.8342811\n",
      "   -1.1605269 ]\n",
      "  [-1.1329347  -1.1696279  -0.9979361  ... -0.79828316  0.78893507\n",
      "   -1.0798246 ]\n",
      "  [-1.0810297  -1.1791006  -0.9668225  ... -0.7584946   0.72082675\n",
      "   -1.0630846 ]]\n",
      "\n",
      " [[-1.3665909  -1.3370295  -1.315973   ... -0.85473686  1.231945\n",
      "   -1.1979498 ]\n",
      "  [-1.3905394  -1.3770318  -1.4413198  ... -0.7270258   1.2442154\n",
      "   -1.182418  ]\n",
      "  [-1.3450726  -1.3405231  -1.2901516  ... -0.7099765   1.1460656\n",
      "   -1.2933781 ]\n",
      "  ...\n",
      "  [-1.229207   -1.1273438  -1.1243563  ... -0.78077406  0.9293864\n",
      "   -1.2193882 ]\n",
      "  [-1.2026738  -1.2344546  -1.0851371  ... -0.85083187  0.8740291\n",
      "   -1.1384457 ]\n",
      "  [-1.1601026  -1.2487254  -1.0535412  ... -0.7934399   0.81707907\n",
      "   -1.1334327 ]]]\n"
     ]
    }
   ],
   "source": [
    "#Make predictions\n",
    "y_pred2 = model2.predict(X_test)\n",
    "\n",
    "# Print predictions\n",
    "print(\"Predictions: \", y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for model1: 0.4892507777663575\n",
      "Weight for model2: 0.5107492222336425\n"
     ]
    }
   ],
   "source": [
    "# Example RMSE values\n",
    "rmse_model1 = 0.40163204073905945\n",
    "rmse_model2 = 0.38472655415534973\n",
    "\n",
    "# Calculate inverse RMSE\n",
    "inv_rmse_model1 = 1 / rmse_model1\n",
    "inv_rmse_model2 = 1 / rmse_model2\n",
    "\n",
    "# Calculate total inverse RMSE\n",
    "total_inv_rmse = inv_rmse_model1 + inv_rmse_model2\n",
    "\n",
    "# Calculate weights\n",
    "weight1 = inv_rmse_model1 / total_inv_rmse\n",
    "weight2 = inv_rmse_model2 / total_inv_rmse\n",
    "\n",
    "print(f\"Weight for model1: {weight1}\")\n",
    "print(f\"Weight for model2: {weight2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.487601   -1.5508908  -1.5797215  ... -1.0820266   1.3013725\n",
      "   -1.4221182 ]\n",
      "  [-1.5119743  -1.5615122  -1.5854913  ... -1.0014912   1.3985965\n",
      "   -1.407223  ]\n",
      "  [-1.5241984  -1.5832283  -1.5629572  ... -1.0307806   1.4694897\n",
      "   -1.5278263 ]\n",
      "  ...\n",
      "  [-1.2897975  -1.3253018  -1.328244   ... -0.9041908   1.1455704\n",
      "   -1.2814664 ]\n",
      "  [-1.347531   -1.3434525  -1.3445156  ... -0.9799099   1.0884601\n",
      "   -1.2145725 ]\n",
      "  [-1.2966654  -1.3368374  -1.2912712  ... -0.9223418   1.0738282\n",
      "   -1.257212  ]]\n",
      "\n",
      " [[-1.4850075  -1.546657   -1.5739461  ... -1.080195    1.2990854\n",
      "   -1.4183836 ]\n",
      "  [-1.5089524  -1.558799   -1.5796573  ... -1.0001627   1.3934169\n",
      "   -1.4029045 ]\n",
      "  [-1.5194274  -1.5783086  -1.5578876  ... -1.0287541   1.4624519\n",
      "   -1.5236545 ]\n",
      "  ...\n",
      "  [-1.2834802  -1.3167408  -1.3212006  ... -0.8980206   1.1390529\n",
      "   -1.2735063 ]\n",
      "  [-1.3398283  -1.3353608  -1.3347564  ... -0.97333086  1.0839342\n",
      "   -1.2077724 ]\n",
      "  [-1.289057   -1.3280973  -1.281653   ... -0.91365016  1.0682971\n",
      "   -1.2491162 ]]\n",
      "\n",
      " [[-1.4894263  -1.5533745  -1.586706   ... -1.078657    1.3051572\n",
      "   -1.4271526 ]\n",
      "  [-1.5154862  -1.5641966  -1.5917794  ... -0.9975067   1.4059436\n",
      "   -1.4105015 ]\n",
      "  [-1.531406   -1.5896378  -1.571703   ... -1.0278339   1.4827571\n",
      "   -1.5305377 ]\n",
      "  ...\n",
      "  [-1.2959331  -1.3324733  -1.3332093  ... -0.91276485  1.1451483\n",
      "   -1.2858282 ]\n",
      "  [-1.3526217  -1.3497177  -1.3535718  ... -0.991442    1.0866607\n",
      "   -1.2192502 ]\n",
      "  [-1.3024936  -1.3446958  -1.2992067  ... -0.93739104  1.0708615\n",
      "   -1.2671139 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1.327575   -1.3187572  -1.3319814  ... -0.84466565  1.1688052\n",
      "   -1.2002628 ]\n",
      "  [-1.3528473  -1.3822722  -1.3750936  ... -0.7460928   1.194999\n",
      "   -1.2222201 ]\n",
      "  [-1.323364   -1.3324783  -1.3199332  ... -0.74503815  1.1696671\n",
      "   -1.3273032 ]\n",
      "  ...\n",
      "  [-1.1375446  -1.0780417  -1.0847273  ... -0.74328524  0.8481112\n",
      "   -1.1189797 ]\n",
      "  [-1.1301476  -1.1187193  -1.0745406  ... -0.8235767   0.81796443\n",
      "   -1.0487974 ]\n",
      "  [-1.0678494  -1.124124   -1.0035053  ... -0.77267194  0.7682438\n",
      "   -1.0462406 ]]\n",
      "\n",
      " [[-1.3720596  -1.3681898  -1.3769249  ... -0.8965849   1.193121\n",
      "   -1.2423503 ]\n",
      "  [-1.3989062  -1.4266549  -1.4225144  ... -0.79358125  1.2406111\n",
      "   -1.2594779 ]\n",
      "  [-1.3738635  -1.381577   -1.3730993  ... -0.79929745  1.220284\n",
      "   -1.3752422 ]\n",
      "  ...\n",
      "  [-1.1739793  -1.1247909  -1.1320295  ... -0.7829056   0.8844013\n",
      "   -1.1578658 ]\n",
      "  [-1.1731726  -1.1634505  -1.1247022  ... -0.8672404   0.8540255\n",
      "   -1.0846751 ]\n",
      "  [-1.1191295  -1.1717836  -1.053297   ... -0.8090855   0.80901223\n",
      "   -1.0913739 ]]\n",
      "\n",
      " [[-1.404982   -1.4100351  -1.4207587  ... -0.9451295   1.2134483\n",
      "   -1.2835746 ]\n",
      "  [-1.4334096  -1.4616463  -1.4669651  ... -0.84437656  1.2827545\n",
      "   -1.289156  ]\n",
      "  [-1.4184949  -1.4257109  -1.4234164  ... -0.8489943   1.2748823\n",
      "   -1.4096928 ]\n",
      "  ...\n",
      "  [-1.2037604  -1.1702589  -1.1769469  ... -0.818464    0.9341649\n",
      "   -1.192945  ]\n",
      "  [-1.2126656  -1.2023857  -1.1784818  ... -0.9055778   0.897345\n",
      "   -1.1202924 ]\n",
      "  [-1.1669004  -1.2157757  -1.1074073  ... -0.84325236  0.85757256\n",
      "   -1.1367683 ]]]\n"
     ]
    }
   ],
   "source": [
    "# Weighted Averaging\n",
    "y_pred_X = (weight1 * y_pred1 + weight2 * y_pred2) / (weight1 + weight2)\n",
    "\n",
    "# Print predictions\n",
    "print(y_pred_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final RMSE:  0.36445731651774077\n",
      "Final MAE:  0.31176446120447365\n",
      "Final MAPE:  127.69303329328051\n",
      "Final Precision:  0.805\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print final evaluation metrics on the test set\n",
    "final_rmse = np.sqrt(mean_squared_error(y_test.flatten(), y_pred_X.flatten()))\n",
    "final_mae = mean_absolute_error(y_test.flatten(), y_pred_X.flatten())\n",
    "final_mape = np.mean(np.abs((y_test.flatten() - y_pred_X.flatten()) / y_test.flatten())) * 100\n",
    "final_precision = precision_score((y_test.flatten() > 0.5).astype(int), (y_pred_X.flatten() > 0.5).astype(int))\n",
    "\n",
    "print(\"Final RMSE: \", final_rmse)\n",
    "print(\"Final MAE: \", final_mae)\n",
    "print(\"Final MAPE: \", final_mape)\n",
    "print(\"Final Precision: \", final_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse transform the predictions and the test data\n",
    "y_pred_inverse = scaler.inverse_transform(y_pred_X.reshape(-1, y_pred_X.shape[-1])).reshape(y_pred_X.shape)\n",
    "y_test_inverse = scaler.inverse_transform(y_test.reshape(-1, y_test.shape[-1])).reshape(y_test.shape)\n",
    "\n",
    "columnsnames=['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5', 'Feature6','Feature7', 'Feature8']\n",
    "\n",
    "## Convert predictions and actual values to separate DataFrames using original column names\n",
    "actual_df = pd.DataFrame(y_test_inverse.reshape(-1, y_test_inverse.shape[-1]), columns=columnsnames)\n",
    "predicted_df = pd.DataFrame(y_pred_inverse.reshape(-1, y_pred_inverse.shape[-1]), columns=columnsnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>Feature3</th>\n",
       "      <th>Feature4</th>\n",
       "      <th>Feature5</th>\n",
       "      <th>Feature6</th>\n",
       "      <th>Feature7</th>\n",
       "      <th>Feature8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1208</td>\n",
       "      <td>86623.6320</td>\n",
       "      <td>84400.4660</td>\n",
       "      <td>1162.3136</td>\n",
       "      <td>422.0</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>0.7723</td>\n",
       "      <td>0.1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1208</td>\n",
       "      <td>86623.6320</td>\n",
       "      <td>84400.4660</td>\n",
       "      <td>1162.3136</td>\n",
       "      <td>422.0</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>0.7723</td>\n",
       "      <td>0.1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1208</td>\n",
       "      <td>86635.5211</td>\n",
       "      <td>84412.6135</td>\n",
       "      <td>1162.3136</td>\n",
       "      <td>422.0</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>0.7722</td>\n",
       "      <td>0.1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1293</td>\n",
       "      <td>89857.0463</td>\n",
       "      <td>87010.3655</td>\n",
       "      <td>1197.5529</td>\n",
       "      <td>442.0</td>\n",
       "      <td>1113.0</td>\n",
       "      <td>0.7758</td>\n",
       "      <td>0.1526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1297</td>\n",
       "      <td>90049.8254</td>\n",
       "      <td>86932.1158</td>\n",
       "      <td>1178.7947</td>\n",
       "      <td>439.0</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>0.7706</td>\n",
       "      <td>0.1535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.1387</td>\n",
       "      <td>92597.5043</td>\n",
       "      <td>90066.2099</td>\n",
       "      <td>1181.6302</td>\n",
       "      <td>449.0</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>0.7577</td>\n",
       "      <td>0.1645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.1386</td>\n",
       "      <td>92571.9423</td>\n",
       "      <td>90039.6155</td>\n",
       "      <td>1181.6302</td>\n",
       "      <td>449.0</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>0.1644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.1386</td>\n",
       "      <td>92571.9423</td>\n",
       "      <td>90039.6155</td>\n",
       "      <td>1181.6302</td>\n",
       "      <td>449.0</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>0.1644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.1387</td>\n",
       "      <td>92597.5043</td>\n",
       "      <td>90066.2099</td>\n",
       "      <td>1181.6302</td>\n",
       "      <td>449.0</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>0.7577</td>\n",
       "      <td>0.1645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.1386</td>\n",
       "      <td>92571.9423</td>\n",
       "      <td>90039.6155</td>\n",
       "      <td>1181.6302</td>\n",
       "      <td>449.0</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>0.1644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature1    Feature2    Feature3   Feature4  Feature5  Feature6  \\\n",
       "0      0.1208  86623.6320  84400.4660  1162.3136     422.0    1083.0   \n",
       "1      0.1208  86623.6320  84400.4660  1162.3136     422.0    1083.0   \n",
       "2      0.1208  86635.5211  84412.6135  1162.3136     422.0    1083.0   \n",
       "3      0.1293  89857.0463  87010.3655  1197.5529     442.0    1113.0   \n",
       "4      0.1297  90049.8254  86932.1158  1178.7947     439.0    1094.0   \n",
       "..        ...         ...         ...        ...       ...       ...   \n",
       "395    0.1387  92597.5043  90066.2099  1181.6302     449.0    1093.0   \n",
       "396    0.1386  92571.9423  90039.6155  1181.6302     449.0    1093.0   \n",
       "397    0.1386  92571.9423  90039.6155  1181.6302     449.0    1093.0   \n",
       "398    0.1387  92597.5043  90066.2099  1181.6302     449.0    1093.0   \n",
       "399    0.1386  92571.9423  90039.6155  1181.6302     449.0    1093.0   \n",
       "\n",
       "     Feature7  Feature8  \n",
       "0      0.7723    0.1413  \n",
       "1      0.7723    0.1413  \n",
       "2      0.7722    0.1413  \n",
       "3      0.7758    0.1526  \n",
       "4      0.7706    0.1535  \n",
       "..        ...       ...  \n",
       "395    0.7577    0.1645  \n",
       "396    0.7579    0.1644  \n",
       "397    0.7579    0.1644  \n",
       "398    0.7577    0.1645  \n",
       "399    0.7579    0.1644  \n",
       "\n",
       "[400 rows x 8 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>Feature3</th>\n",
       "      <th>Feature4</th>\n",
       "      <th>Feature5</th>\n",
       "      <th>Feature6</th>\n",
       "      <th>Feature7</th>\n",
       "      <th>Feature8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.122134</td>\n",
       "      <td>86766.703125</td>\n",
       "      <td>83976.804688</td>\n",
       "      <td>1165.999634</td>\n",
       "      <td>421.160919</td>\n",
       "      <td>1084.445923</td>\n",
       "      <td>0.774756</td>\n",
       "      <td>0.143673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.121633</td>\n",
       "      <td>86697.804688</td>\n",
       "      <td>83945.117188</td>\n",
       "      <td>1166.680420</td>\n",
       "      <td>425.545593</td>\n",
       "      <td>1087.256958</td>\n",
       "      <td>0.776000</td>\n",
       "      <td>0.144102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.121382</td>\n",
       "      <td>86556.945312</td>\n",
       "      <td>84068.859375</td>\n",
       "      <td>1167.063354</td>\n",
       "      <td>423.838409</td>\n",
       "      <td>1086.234619</td>\n",
       "      <td>0.776907</td>\n",
       "      <td>0.140626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.122488</td>\n",
       "      <td>87019.968750</td>\n",
       "      <td>83762.273438</td>\n",
       "      <td>1167.207520</td>\n",
       "      <td>426.527283</td>\n",
       "      <td>1084.979736</td>\n",
       "      <td>0.778141</td>\n",
       "      <td>0.141843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.121701</td>\n",
       "      <td>86721.914062</td>\n",
       "      <td>84147.882812</td>\n",
       "      <td>1169.439209</td>\n",
       "      <td>429.149750</td>\n",
       "      <td>1089.444702</td>\n",
       "      <td>0.778704</td>\n",
       "      <td>0.141760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.128349</td>\n",
       "      <td>88765.062500</td>\n",
       "      <td>86245.343750</td>\n",
       "      <td>1181.656860</td>\n",
       "      <td>437.241943</td>\n",
       "      <td>1098.294678</td>\n",
       "      <td>0.771540</td>\n",
       "      <td>0.152163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.128676</td>\n",
       "      <td>88942.046875</td>\n",
       "      <td>86282.195312</td>\n",
       "      <td>1177.154053</td>\n",
       "      <td>434.705017</td>\n",
       "      <td>1095.778076</td>\n",
       "      <td>0.770360</td>\n",
       "      <td>0.150860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.127966</td>\n",
       "      <td>89235.609375</td>\n",
       "      <td>86188.531250</td>\n",
       "      <td>1175.480591</td>\n",
       "      <td>432.389099</td>\n",
       "      <td>1093.645386</td>\n",
       "      <td>0.770058</td>\n",
       "      <td>0.150280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.127783</td>\n",
       "      <td>89027.226562</td>\n",
       "      <td>86180.109375</td>\n",
       "      <td>1173.588745</td>\n",
       "      <td>430.903046</td>\n",
       "      <td>1090.604736</td>\n",
       "      <td>0.769587</td>\n",
       "      <td>0.152374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.128723</td>\n",
       "      <td>88940.367188</td>\n",
       "      <td>86570.390625</td>\n",
       "      <td>1173.033813</td>\n",
       "      <td>429.668030</td>\n",
       "      <td>1092.780151</td>\n",
       "      <td>0.769078</td>\n",
       "      <td>0.151899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature1      Feature2      Feature3     Feature4    Feature5  \\\n",
       "0    0.122134  86766.703125  83976.804688  1165.999634  421.160919   \n",
       "1    0.121633  86697.804688  83945.117188  1166.680420  425.545593   \n",
       "2    0.121382  86556.945312  84068.859375  1167.063354  423.838409   \n",
       "3    0.122488  87019.968750  83762.273438  1167.207520  426.527283   \n",
       "4    0.121701  86721.914062  84147.882812  1169.439209  429.149750   \n",
       "..        ...           ...           ...          ...         ...   \n",
       "395  0.128349  88765.062500  86245.343750  1181.656860  437.241943   \n",
       "396  0.128676  88942.046875  86282.195312  1177.154053  434.705017   \n",
       "397  0.127966  89235.609375  86188.531250  1175.480591  432.389099   \n",
       "398  0.127783  89027.226562  86180.109375  1173.588745  430.903046   \n",
       "399  0.128723  88940.367188  86570.390625  1173.033813  429.668030   \n",
       "\n",
       "        Feature6  Feature7  Feature8  \n",
       "0    1084.445923  0.774756  0.143673  \n",
       "1    1087.256958  0.776000  0.144102  \n",
       "2    1086.234619  0.776907  0.140626  \n",
       "3    1084.979736  0.778141  0.141843  \n",
       "4    1089.444702  0.778704  0.141760  \n",
       "..           ...       ...       ...  \n",
       "395  1098.294678  0.771540  0.152163  \n",
       "396  1095.778076  0.770360  0.150860  \n",
       "397  1093.645386  0.770058  0.150280  \n",
       "398  1090.604736  0.769587  0.152374  \n",
       "399  1092.780151  0.769078  0.151899  \n",
       "\n",
       "[400 rows x 8 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
